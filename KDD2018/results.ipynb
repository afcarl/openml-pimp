{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import collections\n",
    "import copy\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy.stats\n",
    "\n",
    "# mapping from casual name to directory where it is saved\n",
    "classifiers = {\n",
    "  'random forest': '6969/vanilla', \n",
    "  'adaboost':      '6970/vanilla', \n",
    "  'svm (rbf)':     '7707/kernel_rbf', \n",
    "  'svm (sigmoid)': '7707/kernel_sigmoid'\n",
    "}\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Marginal Contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def rank_dict(dictionary, reverse=False):\n",
    "    dictionary = copy.copy(dictionary)\n",
    "    if reverse:\n",
    "        for key in dictionary.keys():\n",
    "            dictionary[key] = 1 - dictionary[key]\n",
    "    sortdict = collections.OrderedDict(sorted(dictionary.items()))\n",
    "    ranks = scipy.stats.rankdata(list(sortdict.values()))\n",
    "    result = {}\n",
    "    for idx, (key, value) in enumerate(sortdict.items()):\n",
    "        result[key] = ranks[idx]\n",
    "    return result\n",
    "\n",
    "\n",
    "def sum_dict_values(a, b, allow_subsets=False):\n",
    "    result = {}\n",
    "    a_total = sum(a.values())\n",
    "    b_total = sum(b.values())\n",
    "    a_min_b = set(a.keys()) - set(b.keys())\n",
    "    b_min_a = set(b.keys()) - set(a.keys())\n",
    "    if len(b_min_a) > 0:\n",
    "        raise ValueError('dict b got illegal keys: %s' %str(b_min_a))\n",
    "    if not allow_subsets and len(a_min_b):\n",
    "        raise ValueError('keys not the same')\n",
    "    for idx in a.keys():\n",
    "        if idx in b:\n",
    "            result[idx] = a[idx] + b[idx]\n",
    "        else:\n",
    "            result[idx] = a[idx]\n",
    "    if sum(result.values()) != a_total + b_total:\n",
    "        raise ValueError()\n",
    "    return result\n",
    "\n",
    "\n",
    "def divide_dict_values(d, denominator):\n",
    "    result = {}\n",
    "    for idx in d.keys():\n",
    "        result[idx] = d[idx] / denominator\n",
    "    return result\n",
    "\n",
    "\n",
    "def format_name(name):\n",
    "    mapping_plain = {\n",
    "        'strategy': 'imputation',\n",
    "        'max_features': 'max. features',\n",
    "        'min_samples_leaf': 'min. samples leaf',\n",
    "        'min_samples_split': 'min. samples split',\n",
    "        'criterion': 'split criterion',\n",
    "        'learning_rate': 'learning rate',\n",
    "        'max_depth': 'max. depth',\n",
    "        'n_estimators': 'iterations',\n",
    "        'algorithm': 'algorithm',\n",
    "    }\n",
    "    mapping_short = {\n",
    "        'strategy': 'imputation',\n",
    "        'max_features': 'max. feat.',\n",
    "        'min_samples_leaf': 'samples leaf',\n",
    "        'min_samples_split': 'samples split',\n",
    "        'criterion': 'split criterion',\n",
    "        'learning_rate': 'learning r.',\n",
    "        'max_depth': 'max. depth',\n",
    "        'n_estimators': 'iterations',\n",
    "        'algorithm': 'algo.',\n",
    "    }\n",
    "\n",
    "    parts = name.split('__')\n",
    "    for idx, part in enumerate(parts):\n",
    "        if part in mapping_plain:\n",
    "            if len(parts) < 3:\n",
    "                parts[idx] = mapping_plain[part]\n",
    "            else:\n",
    "                parts[idx] = mapping_short[part]\n",
    "\n",
    "    return ' / '.join(parts)\n",
    "\n",
    "\n",
    "def marginal_plots(sorted_values, keys, fig_title):\n",
    "    plt.figure()\n",
    "    plt.violinplot(list(sorted_values), list(range(len(sorted_values))))\n",
    "    plt.plot([-0.5, len(sorted_values) - 0.5], [0, 0], 'k-', linestyle='--', lw=1)\n",
    "    keys = [format_name(key) for key in keys]\n",
    "    plt.xticks(list(range(len(sorted_values))), list(keys), rotation=45, ha='right')\n",
    "    plt.ylabel('marginal contribution')\n",
    "    # plt.title(fig_title)\n",
    "    print(fig_title)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def determine_relevant(data, max_items=None, max_interactions=None):\n",
    "    from statistics import median\n",
    "    \n",
    "    sorted_values = []\n",
    "    keys = []\n",
    "    interactions_seen = 0\n",
    "    for key in sorted(data, key=lambda k: median(data[k]), reverse=True):\n",
    "        if '__' in key:\n",
    "            interactions_seen += 1\n",
    "            if interactions_seen > max_interactions:\n",
    "                continue\n",
    "\n",
    "        sorted_values.append(data[key])\n",
    "        keys.append(key)\n",
    "\n",
    "    if max_items is not None:\n",
    "        sorted_values = sorted_values[:max_items]\n",
    "        keys = keys[:max_items]\n",
    "\n",
    "    return sorted_values, keys\n",
    "\n",
    "def obtain_marginal_contributions(result_directory):\n",
    "    all_ranks = dict()\n",
    "    all_tasks = list()\n",
    "    total_ranks = None\n",
    "    num_tasks = 0\n",
    "    marginal_contribution = collections.defaultdict(list)\n",
    "\n",
    "    for task_id in os.listdir(result_directory):\n",
    "        task_dir = os.path.join(result_directory, task_id)\n",
    "        if os.path.isdir(task_dir):\n",
    "            pimp_file = os.path.join(task_dir, 'pimp_values_fanova.json')\n",
    "            interaction_file = os.path.join(task_dir, 'pimp_values_fanova_interaction.json')\n",
    "\n",
    "            if os.path.isfile(pimp_file) and os.path.isfile(interaction_file):\n",
    "                hyperparameters = json.loads(open(pimp_file).read())\n",
    "                hyperparameters.update(json.loads(open(interaction_file).read()))\n",
    "\n",
    "                for hyperparameter, value in hyperparameters.items():\n",
    "                    parts = hyperparameter.split('__')\n",
    "                    if sorted(parts) != parts: continue\n",
    "\n",
    "                    marginal_contribution[hyperparameter].append(value)\n",
    "                all_tasks.append(task_id)\n",
    "\n",
    "                all_ranks[task_id] = hyperparameters\n",
    "                ranks = rank_dict(hyperparameters, reverse=True)\n",
    "                if total_ranks is None:\n",
    "                    total_ranks = ranks\n",
    "                else:\n",
    "                    total_ranks = sum_dict_values(total_ranks, ranks, allow_subsets=False)\n",
    "                    num_tasks += 1\n",
    "    total_ranks = divide_dict_values(total_ranks, num_tasks)\n",
    "    return total_ranks, marginal_contribution, all_tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for classifier, directory_suffix in classifiers.items():\n",
    "    total_ranks, marginal_contribution, _ = obtain_marginal_contributions('data/fanova/' + directory_suffix)\n",
    "    sorted_values, keys = determine_relevant(marginal_contribution, max_interactions=3)\n",
    "    marginal_plots(sorted_values, keys, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Most important hyperparameter per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_axis_feature = 'NumberOfInstances'\n",
    "y_axis_feature = 'NumberOfFeatures'\n",
    "\n",
    "# consistent colors with the other plot\n",
    "colors = {\n",
    "    '6969/vanilla': {'min_samples_leaf': '#ff61c3', 'max_features': '#db72fb', 'criterion': '#d19100', 'bootstrap': '#619cff', 'max_features__min_samples_leaf': '#00c19f'},\n",
    "    '6970/vanilla': {'max_depth': '#ff61cc', 'algorithm': '#7cae00', 'learning_rate': '#c77cff', 'learning_rate__max_depth': '#00a9ff', 'algorithm__max_depth': '#00bfc4'},\n",
    "    '7707/kernel_rbf': {'gamma': '#ff61cc', 'gamma_tol': '#00bfc4', 'C': '#c77cff', 'C_gamma': '#00a9ff'},\n",
    "    '7707/kernel_sigmoid': {'gamma': '#ff61c3', 'gamma_tol': '#00c19f', 'tol': '#93aa00', 'coef0':'#00ba38', 'C_gamma':'#db72fb'},\n",
    "}\n",
    "\n",
    "\n",
    "for classifier, directory_suffix in classifiers.items():\n",
    "    x_vals = {}\n",
    "    y_vals = {}\n",
    "    area = {}\n",
    "    \n",
    "    directory = 'data/fanova/' + directory_suffix\n",
    "    task_qualities = json.load(open('data/fanova/task_qualities.json', 'r'))\n",
    "    for task_id in os.listdir(directory):\n",
    "        task_dir = os.path.join(directory, task_id)\n",
    "        if not os.path.isdir(task_dir):\n",
    "            continue\n",
    "        pimp_file = os.path.join(task_dir, 'pimp_values_fanova.json')\n",
    "        interaction_file = os.path.join(task_dir, 'pimp_values_fanova_interaction.json')\n",
    "        \n",
    "        if not (os.path.isfile(pimp_file) and os.path.isfile(interaction_file)):\n",
    "            continue\n",
    "        \n",
    "        hyperparameters = json.load(open(pimp_file, 'r'))\n",
    "        hyperparameters.update(json.load(open(interaction_file, 'r')))\n",
    "        \n",
    "        most_important = max(hyperparameters, key=hyperparameters.get) \n",
    "        value = hyperparameters[most_important]\n",
    "        \n",
    "        if most_important not in x_vals:\n",
    "            x_vals[most_important] = []\n",
    "            y_vals[most_important] = []\n",
    "            area[most_important] = []\n",
    "        x_vals[most_important].append(float(task_qualities[task_id][x_axis_feature]))\n",
    "        y_vals[most_important].append(float(task_qualities[task_id][y_axis_feature]))\n",
    "        area[most_important].append(float(value) * 50)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plotted_items = []\n",
    "    legend_keys = []\n",
    "    for param in x_vals.keys():\n",
    "        occurances = len(x_vals[param])\n",
    "        if param in colors[directory_suffix]:\n",
    "            current = plt.scatter(x_vals[param], y_vals[param], c=colors[directory_suffix][param], s=area[param], alpha=0.9)\n",
    "        else:\n",
    "            current = plt.scatter(x_vals[param], y_vals[param], s=area[param], alpha=1.0)\n",
    "        plotted_items.append(current)\n",
    "        legend_keys.append(format_name(param))\n",
    "    \n",
    "\n",
    "    legend = plt.legend(plotted_items, legend_keys, scatterpoints=1, loc='upper right')\n",
    "    for idx in range(len(plotted_items)):\n",
    "        legend.legendHandles[idx]._sizes = [50]\n",
    "    \n",
    "    print(classifier)\n",
    "    # dimensions of the datasets\n",
    "    plt.axis((450,100000,3,2100))\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "    plt.xlabel(x_axis_feature, fontsize='xx-large')\n",
    "    plt.ylabel(y_axis_feature, fontsize='xx-large')\n",
    "    plt.show()\n",
    "    # plt.savefig('result_' + classifier + '.pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Verification\n",
    "The plots in the submission are generated with an external plotting library. To keep the notebook understandable, we will just display the dataframes with results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for classifier, directory_suffix in classifiers.items():\n",
    "    \n",
    "    file = 'data/verification/' + directory_suffix + '/random_search.pkl'\n",
    "    if os.path.isfile(file):\n",
    "        dataframe = pickle.load(open(file, 'rb'))\n",
    "        print(classifier)\n",
    "        print(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Prior experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_violin(results):\n",
    "    data = []\n",
    "    kde_wins = 0\n",
    "    uni_wins = 0\n",
    "    draws = 0\n",
    "    dataframe = pd.DataFrame(columns=['task_id', 'mean_result_kde', 'mean_result_uniform', 'difference'])\n",
    "    \n",
    "    for task_id in results:\n",
    "        if len(results[task_id]) == 2 and 'uniform' in results[task_id] and 'kde' in results[task_id] and len(results[task_id]['kde']) > 0 and len(results[task_id]['uniform']) > 0:\n",
    "            scores_kde = sum(results[task_id]['kde'].values()) / len(results[task_id]['kde'])\n",
    "            scores_uniform = sum(results[task_id]['uniform'].values()) / len(results[task_id]['uniform'])\n",
    "            current_difference = scores_kde - scores_uniform\n",
    "            data.append(current_difference)\n",
    "            current_row = {'task_id': task_id, 'mean_result_kde': scores_kde, 'mean_result_uniform': scores_uniform, 'difference': current_difference}\n",
    "            dataframe = dataframe.append(current_row, ignore_index=True)\n",
    "    dataframe = dataframe.set_index('task_id')\n",
    "    \n",
    "    plt.figure(figsize=(2, 6))\n",
    "    plt.tick_params(axis='x', which='both', bottom='off', top='off', labelbottom='off')\n",
    "    plt.plot([0.5, 1.5], [0, 0], 'k-', linestyle='--', lw=1)\n",
    "    plt.violinplot(data)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "for classifier, directory_suffix in classifiers.items():\n",
    "    directory = 'data/priors/' + directory_suffix\n",
    "    if not os.path.isfile(directory + '/cache_test.pkl'):\n",
    "        raise ValueError('Could not find cache file:', directory + '/cache_test.pkl')\n",
    "    cache_results_test = pickle.load(open(directory + '/cache_test.pkl', 'rb'))\n",
    "    print(classifier)\n",
    "    plot_violin(cache_results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pimp)",
   "language": "python",
   "name": "pimp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
